---
title: Claude Code × Local LLM 連携メモ
tags: ClaudeCode ollama LocalLLM
author: nakamasato
slide: false
---
## はじめに

Claude Codeは、Anthropic社が開発したターミナル上で動作するAIコーディングアシスタントです。通常はAnthropicのClaudeモデルのみを使用しますが、`claude-bridge`を使用することで、OllamaなどのローカルLLMと連携させることができます。

この記事では、`@mariozechner/claude-bridge`を使ってClaude CodeとOllamaのローカルLLMを連携させる方法を解説します。

## 必要な環境

- Node.js
- npm
- macOS、Linux、またはWindows（今回はMacOS）

## 1. Ollamaのインストールと起動

### Ollamaのインストール

公式サイトからOllamaをダウンロードしてインストールします。

**macOS:**
```bash
brew install --cask ollama
```

**Linux:**
```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Windows:**
公式サイト（https://ollama.com/download）からインストーラーをダウンロードして実行

### Ollamaの起動

```bash
ollama serve
```

デフォルトでは `http://localhost:11434` でAPIサーバーが起動します。

### モデルのダウンロード

今回は軽量でありながら高性能な`qwen3:1.7b`モデルを使用します。

```bash
ollama pull qwen3:1.7b
```

モデルの動作確認：
```bash
ollama run qwen3:1.7b
```

## 2. claude-bridgeのインストール

```bash
npm install -g @mariozechner/claude-bridge
```

## 3. claude-bridgeの起動

以下のコマンドでclaude-bridgeを起動します：

```bash
OPENAI_API_KEY=dummy claude-bridge openai qwen3:1.7b --baseURL http://localhost:11434/v1
```

パラメータの説明：
- `OPENAI_API_KEY=dummy`: OpenAI API形式での通信のため、ダミーのAPIキーを設定
- `openai`: プロバイダー形式を指定（OpenAI互換APIとして動作）
- `qwen3:1.7b`: 使用するOllamaモデル名
- `--baseURL http://localhost:11434/v1`: OllamaのAPIエンドポイント

## 4. 動作確認

### 基本的な質問

```
> 日本の首都はどこですか

⏺ Tokyo is the capital city of Japan. It is located in the country of Japan.
```

シンプルな質問に対して、適切な回答が得られました。

「アメリカの首都は」と効いてみるとなぜかWebSearchが使われてしまいました。

```
> アメリカの首都は

⏺ The tools include WebSearch, which allows searching the web and returning results. Since the user is asking
  for geographical information, WebSearch seems appropriate. The parameters for WebSearch require a query,
  allowed_domains, and blocked_domains. The query here is "アメリカの首都は", so I'll use that. The
  allowed_domains might not be necessary if the search is general, but maybe including the domain could help.
  However, since the user didn't specify any particular domains, I'll just use the query. The blocked_domains
  are also not needed here. So I'll call WebSearch with the query "アメリカの首都は".

⏺ Web Search("アメリカの首都は")
  ⎿  Error: Cannot specify both allowed_domains and blocked_domains in the same request
```

この例では、ローカルLLMがWeb検索ツールを呼び出そうとしましたが、パラメータの設定でエラーが発生しています。

Limitationにかかれていましたが、Web Searchは使えません。（この時点で応用性がそこまでなさそうだったので検証をやめました。）

## claude-bridgeの仕組み

`claude-bridge`は、以下のように動作します：

1. **プロトコル変換**: Claude CodeはAnthropicのAPI形式で通信しますが、claude-bridgeがこれをOpenAI互換形式に変換
2. **ローカルLLMとの通信**: 変換されたリクエストをOllamaのAPIエンドポイントに送信
3. **レスポンス変換**: OllamaからのレスポンスをClaude Code形式に変換して返却

## 利点と制限事項

### 利点

- **プライバシー**: すべての処理がローカルで完結
- **コスト削減**: 外部APIの使用料金が不要
- **オフライン動作**: インターネット接続不要
- **カスタマイズ**: 自分のデータでファインチューニングしたモデルも使用可能

### 制限事項

- **ツール機能**: Web検索やファイル操作などの一部ツールが正常に動作しない場合がある
- **パフォーマンス**: Claude本家と比較して応答精度や速度に差がある場合がある
- **互換性**: すべてのClaude Code機能が完全に互換するわけではない

Ref: [Limitation](https://github.com/badlogic/lemmy/tree/main/apps/claude-bridge#limitations)

> This is a glorified hack that pretends other models are Claude. Here's what breaks:
>
> Completely Broken:
>
> 🚫 Token usage/cost reporting (Claude Code's displays will lie to you)
> 🚫 Image uploads (drag/drop, paste, file paths - Claude Code expects Anthropic's servers)
> 🚫 Input caching (Claude Code's prompt caching isn't implemented - enjoy higher costs!)
> 🚫 Web search/fetch tools (Anthropic-specific magic)
> Somewhat Janky:
>
> 🤷 Model-specific features don't translate (Claude's artifacts, GPT's reasoning modes)
> 🤷 Thinking/reasoning output formatting differs between providers
> 🤷 Error messages might be cryptic (provider auth failures won't surface clearly)
> 🤷 Tool schemas get converted (JSON Schema ↔ Zod) - usually works, sometimes doesn't
> 🤷 Streaming behavior has subtle differences despite SSE format conversion

## その他の設定オプション

### デバッグモード

```bash
OPENAI_API_KEY=dummy claude-bridge openai qwen3:1.7b --baseURL http://localhost:11434/v1 --debug
```

### 他のモデルを使用

```bash
# より大きなモデルを使用する場合
ollama pull llama3.2:3b
OPENAI_API_KEY=dummy claude-bridge openai llama3.2:3b --baseURL http://localhost:11434/v1
```

### OpenRouterとの連携

```bash
claude-bridge openai gpt-4o --baseURL https://openrouter.ai/api/v1 --apiKey sk-or-your-key
```

## まとめ

`claude-bridge`を使用することで、Claude CodeとローカルLLMを連携させることができました。完全な互換性はありませんが、とりあえず動かすことはできました。
あまり用途はなさそうですが、一旦連携したメモとして残しておきます。


## 参考リンク

- [Ollama公式サイト](https://ollama.com/)
- [Claude Code公式ドキュメント](https://docs.anthropic.com/en/docs/build-with-claude/claude-code)
- [claude-bridge GitHubリポジトリ](https://github.com/badlogic/lemmy/tree/main/apps/claude-bridge)
- [npm: @mariozechner/claude-bridge](https://www.npmjs.com/package/@mariozechner/claude-bridge)

